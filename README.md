# Awesome NeurIPS 2025 Vision-Language Models (VLMs) ğŸš€

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![NeurIPS 2025](https://img.shields.io/badge/NeurIPS-2025-blue.svg)](https://neurips.cc/Conferences/2025)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/)

A curated collection of **Vision-Language Model (VLM)** papers accepted at NeurIPS 2025 with GitHub links.

> **Note**: This list contains 400 papers from the [NeurIPS 2025 Vision Models & Multimodal track](https://neurips.cc/virtual/2025/loc/san-diego/papers.html?filter=topic&search=Computer+Vision-%3EVision+Models+%26+Multimodal).

---

## ğŸ“‘ Table of Contents
- [âš¡ Efficient & Lightweight VLMs](#-efficient--lightweight-vlms)
- [ğŸ¥ Video Understanding & Generation](#-video-understanding--generation)
- [ğŸ‘ï¸ Perception & Grounding](#-perception--grounding)
- [ğŸ“Š Benchmarks & Evaluation](#-benchmarks--evaluation)
- [ğŸ”„ Multimodal Alignment & Pre-training](#-multimodal-alignment--pre-training)
- [ğŸ–¼ï¸ Generation & Editing](#-generation--editing)
- [ğŸ›¡ï¸ Safety, Trustworthiness & Hallucination](#-safety-trustworthiness--hallucination)
- [ğŸ¤– Embodied AI & Robotics](#-embodied-ai--robotics)
- [ğŸ§Š 3D & Point Clouds](#-3d--point-clouds)
- [ğŸ§  Reasoning & Chain-of-Thought](#-reasoning--chain-of-thought)
- [ğŸ©º Medical & Scientific](#-medical--scientific)
- [ğŸ“š Other VLM Papers](#-other-vlm-papers)

---

## âš¡ Efficient & Lightweight VLMs

| Paper | Links |
|-------|-------|
| **Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/115558) Â· [GitHub](https://github.com/EmbodiedCity/NeurIPS2025-Balanced-Token-Pruning) |
| **Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs** | [Paper](https://neurips.cc/virtual/2025/poster/119383) Â· [Project](https://theia4869.com/CDPruner/) |
| **DyMU: Dynamic Merging and Virtual Unmerging for Efficient Variable-Length VLMs** | [Paper](https://neurips.cc/virtual/2025/poster/115195) Â· [Project](https://mikewangwzhl.github.io/dymu/) |
| **Efficient RAW Image Deblurring with Adaptive Frequency Modulation** | [Paper](https://neurips.cc/virtual/2025/poster/116988) Â· [GitHub](https://github.com/WenlongJiao/FrENet) |
| **Efficient Rectified Flow for Image Fusion** | [Paper](https://neurips.cc/virtual/2025/poster/117923) |
| **Elevating Visual Perception in Multimodal LLMs with Visual Embedding Distillation** | [Paper](https://neurips.cc/virtual/2025/poster/119448) Â· [GitHub](https://github.com/SHI-Labs/OLA-VLM) |
| **FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering** | [Paper](https://neurips.cc/virtual/2025/poster/119637) Â· [Project](https://focus-mllm-vqa.github.io/) |
| **Glance2Gaze: Efficient Vision-Language Models from Glance Fusion to Gaze Compression** | [Paper](https://neurips.cc/virtual/2025/poster/116704) |
| **Hawaii: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/118565) Â· [Project](http://yimuwangcs.github.io/projects/neurips25_hawaii/index.html) |
| **Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior** | [Paper](https://neurips.cc/virtual/2025/poster/115473) |
| **MixPrompt: Efficient Mixed Prompting for Multimodal Semantic Segmentation** | [Paper](https://neurips.cc/virtual/2025/poster/116430) |
| **NormFit: A Lightweight Solution for Few-Shot Federated Learning with Non-IID Data** | [Paper](https://neurips.cc/virtual/2025/poster/118560) |
| **QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/115710) Â· [GitHub](https://github.com/SAI-Lab-NYU/QSVD) |
| **REN: Fast and Efficient Region Encodings from Patch-Based Image Encoders** | [Paper](https://neurips.cc/virtual/2025/poster/115859) Â· [Project](https://region-encoder.github.io/) |
| **SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/116033) |
| **VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking** | [Paper](https://neurips.cc/virtual/2025/poster/119987) |
| **Vision-centric Token Compression in Large Language Model** | [Paper](https://neurips.cc/virtual/2025/poster/117407) |
| **VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning** | [Paper](https://neurips.cc/virtual/2025/poster/118060) Â· [GitHub](https://github.com/dvlab-research/VisionThink) |
| **Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering** | [Paper](https://neurips.cc/virtual/2025/poster/119476) |

## ğŸ¥ Video Understanding & Generation

| Paper | Links |
|-------|-------|
| **3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model** | [Paper](https://neurips.cc/virtual/2025/poster/115898) Â· [Project](https://3dllm-mem.github.io/) |
| **A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking** | [Paper](https://neurips.cc/virtual/2025/poster/116108) Â· [Project](https://vfbench.github.io/) |
| **Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/118214) Â· [Project](https://clic-compositional-clip.github.io/) |
| **Audio-Sync Video Generation with Multi-Stream Temporal Control** | [Paper](https://neurips.cc/virtual/2025/poster/120270) Â· [Project](https://hjzheng.net/projects/MTV/) |
| **BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning** | [Paper](https://neurips.cc/virtual/2025/poster/115146) |
| **Bisecle: Binding and Separation in Continual Learning for Video Language Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/116080) Â· [GitHub](https://github.com/cruiseresearchgroup/Bisecle) |
| **CausalVTG: Towards Robust Video Temporal Grounding via Causal Inference** | [Paper](https://neurips.cc/virtual/2025/poster/116019) |
| **Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening** | [Paper](https://neurips.cc/virtual/2025/poster/116636) Â· [Project](https://bpiyush.github.io/lift-website/) |
| **CineTechBench: A Benchmark for Cinematographic Technique Understanding and Generation** | [Paper](https://neurips.cc/virtual/2025/poster/121706) Â· [GitHub](https://github.com/PRIS-CV/CineTechBench) |
| **Collaborating Vision, Depth, and Thermal Signals for Multi-Modal Tracking: Dataset and Algorithm** | [Paper](https://neurips.cc/virtual/2025/poster/121786) Â· [Project](https://xuefeng-zhu5.github.io/RGBDT500/) |
| **ConViS-Bench: Estimating Video Similarity  Through Semantic Concepts** | [Paper](https://neurips.cc/virtual/2025/poster/121680) Â· [Project](https://benedettaliberatori.github.io/convisbench/) |
| **DOVTrack: Data-Efficient Open-Vocabulary Tracking** | [Paper](https://neurips.cc/virtual/2025/poster/119227) |
| **Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/116039) |
| **DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO** | [Paper](https://neurips.cc/virtual/2025/poster/120134) |
| **EgoDTM: Towards 3D-Aware Egocentric Video-Language Pretraining** | [Paper](https://neurips.cc/virtual/2025/poster/115822) |
| **EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs** | [Paper](https://neurips.cc/virtual/2025/poster/121628) Â· [GitHub](https://github.com/ayiyayi/EgoExoBench) |
| **EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT** | [Paper](https://neurips.cc/virtual/2025/poster/119530) |
| **EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition** | [Paper](https://neurips.cc/virtual/2025/poster/121788) Â· [GitHub](https://github.com/laion-ai/emonet-face) |
| **Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/115987) |
| **Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions** | [Paper](https://neurips.cc/virtual/2025/poster/119758) Â· [GitHub](https://github.com/JiH00nKw0n/READ-CLIP) |
| **Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders** | [Paper](https://neurips.cc/virtual/2025/poster/120159) |
| **Event-Guided Consistent Video Enhancement with Modality-Adaptive Diffusion Pipeline** | [Paper](https://neurips.cc/virtual/2025/poster/119370) |
| **ExAct: A Video-Language Benchmark for Expert Action Analysis** | [Paper](https://neurips.cc/virtual/2025/poster/121524) Â· [Project](https://texaser.github.io/exact_project_page/) |
| **Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video** | [Paper](https://neurips.cc/virtual/2025/poster/120140) Â· [Project](https://zhangyl4.github.io/publications/eyes-wide-open/) |
| **FAVOR-Bench: A Comprehensive Benchmark for Fine-Grained Video Motion Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121776) Â· [Project](https://favor-bench.github.io/) |
| **Fact-R1: Towards Explainable Video Misinformation Detection with Deep Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/119113) Â· [GitHub](https://github.com/zfr00/Fact-R1) |
| **FastVID: Dynamic Density Pruning for Fast Video Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/120084) Â· [GitHub](https://github.com/LunarShen/FastVID) |
| **Fire360: A Benchmark for Robust Perception and Episodic Memory in Degraded 360Â° Firefighting Video** | [Paper](https://neurips.cc/virtual/2025/poster/121673) |
| **FlexSelect: Flexible Token Selection for Efficient  Long Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/120343) Â· [GitHub](https://github.com/yunzhuzhang0918/flexselect) |
| **FlowFeat: Pixel-Dense Embedding of Motion Profiles** | [Paper](https://neurips.cc/virtual/2025/poster/116730) |
| **From Play to Replay: Composed Video Retrieval for Temporally Fine-Grained Videos** | [Paper](https://neurips.cc/virtual/2025/poster/121717) Â· [Project](https://animesh-007.github.io/TF-CoVR-WEBSITE/) |
| **Fully Spiking Neural Networks for Unified Frame-Event Object Tracking** | [Paper](https://neurips.cc/virtual/2025/poster/119010) |
| **HMVLM:Human Motion-Vision-Language Model via MoE LoRA** | [Paper](https://neurips.cc/virtual/2025/poster/118923) |
| **HoliTom: Holistic Token Merging for Fast Video Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/119772) |
| **HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios** | [Paper](https://neurips.cc/virtual/2025/poster/115245) |
| **Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models** | [Paper](https://neurips.cc/virtual/2025/poster/121495) Â· [Project](https://impromptu-vla.c7w.tech/) |
| **Improve Temporal Reasoning in Multimodal Large Language Models via Video Contrastive Decoding** | [Paper](https://neurips.cc/virtual/2025/poster/120105) |
| **In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting** | [Paper](https://neurips.cc/virtual/2025/poster/121584) Â· [Project](https://taiyi98.github.io/projects/EgoGazeVQA/) |
| **InfMasking: Unleashing Synergistic Information  by Contrastive Multimodal Interactions** | [Paper](https://neurips.cc/virtual/2025/poster/119809) Â· [GitHub](https://github.com/brightest66/InfMasking) |
| **InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/116667) |
| **Intend to Move: A Multimodal Dataset for Intention-Aware Human Motion Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121855) Â· [Project](https://ummaaa.github.io/intend-to-move/) |
| **JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation** | [Paper](https://neurips.cc/virtual/2025/poster/118457) Â· [Project](https://javisverse.github.io/JavisGPT-page) |
| **Kinaema: a recurrent sequence model for memory and pose in motion** | [Paper](https://neurips.cc/virtual/2025/poster/115962) Â· [Project](https://europe.naverlabs.com/kinaema) |
| **Learning Human-Object Interaction as Groups** | [Paper](https://neurips.cc/virtual/2025/poster/115110) Â· [GitHub](https://github.com/JiajunHong1/GroupHOI) |
| **Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors** | [Paper](https://neurips.cc/virtual/2025/poster/116035) Â· [Project](https://lavi-lab.github.io/VG-LLM) |
| **LiveStar: Live Streaming Assistant for Real-World Online Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/119920) Â· [GitHub](https://github.com/yzy-bupt/LiveStar) |
| **LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/118564) |
| **MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks** | [Paper](https://neurips.cc/virtual/2025/poster/119257) Â· [Project](https://schowdhury671.github.io/magnet_project/) |
| **MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation** | [Paper](https://neurips.cc/virtual/2025/poster/118979) Â· [Project](https://zhoubohan0.github.io/MEg0Hand) |
| **MME-VideoOCR: Evaluating OCR-Based Capabilities of Multimodal LLMs in Video Scenarios** | [Paper](https://neurips.cc/virtual/2025/poster/121517) |
| **MR. Video: MapReduce as an Effective Principle for Long Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/119673) |
| **MUVR: A Multi-Modal Untrimmed Video Retrieval Benchmark with Multi-Level Visual Correspondence** | [Paper](https://neurips.cc/virtual/2025/poster/121621) |
| **MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/121623) |
| **Meta CLIP 2: A Worldwide Scaling Recipe** | [Paper](https://neurips.cc/virtual/2025/poster/117255) Â· [Project](https://meta-clip.github.io/) |
| **Mitigating Hallucination in VideoLLMs via Temporal-Aware Activation Engineering** | [Paper](https://neurips.cc/virtual/2025/poster/119674) |
| **Mitigating Semantic Collapse in Partially Relevant Video Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/117567) |
| **Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation** | [Paper](https://neurips.cc/virtual/2025/poster/120356) |
| **MoniTor: Exploiting Large Language Models with Instruction for Online Video Anomaly Detection** | [Paper](https://neurips.cc/virtual/2025/poster/119803) |
| **MotionBind: Multi-Modal Human Motion Alignment for Retrieval, Recognition, and Generation** | [Paper](https://neurips.cc/virtual/2025/poster/115690) Â· [Project](https://vidal-lab.github.io/MotionBind/) |
| **Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration** | [Paper](https://neurips.cc/virtual/2025/poster/115325) |
| **OSKAR: Omnimodal Self-supervised Knowledge Abstraction and Representation** | [Paper](https://neurips.cc/virtual/2025/poster/118547) |
| **OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121406) Â· [Project](https://rbler1234.github.io/OSTBench.github.io/) |
| **OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions** | [Paper](https://neurips.cc/virtual/2025/poster/115393) Â· [Project](https://omniresponse.github.io/) |
| **One Token per Highly Selective Frame: Towards Extreme Compression for Long Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/117133) |
| **One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution** | [Paper](https://neurips.cc/virtual/2025/poster/117234) |
| **Perceive Anything: Recognize, Explain, Caption, and Segment Anything in Images and Videos** | [Paper](https://neurips.cc/virtual/2025/poster/115989) Â· [Project](https://perceive-anything.github.io/) |
| **ROVER: Recursive Reasoning Over Videos with Vision-Language Models for Embodied Tasks** | [Paper](https://neurips.cc/virtual/2025/poster/118368) Â· [Project](https://rover-vlm.github.io/) |
| **RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video** | [Paper](https://neurips.cc/virtual/2025/poster/121690) Â· [Project](https://ljungang.github.io/RTV-Bench) |
| **Rebalancing Contrastive Alignment with Bottlenecked Semantic Increments in Text-Video Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/119628) |
| **Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/120237) |
| **SAMA: Towards Multi-Turn Referential Grounded Video Chat with Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/117034) Â· [GitHub](https://github.com/sunye23/SAMA) |
| **STAR: Spatial-Temporal Tracklet Matching for Multi-Object Tracking** | [Paper](https://neurips.cc/virtual/2025/poster/116808) |
| **STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving** | [Paper](https://neurips.cc/virtual/2025/poster/121664) Â· [Project](https://lrp-ivc.github.io/STSBench/) |
| **Scaling RL to Long Videos** | [Paper](https://neurips.cc/virtual/2025/poster/117803) Â· [GitHub](https://github.com/NVlabs/Long-RL) |
| **Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals** | [Paper](https://neurips.cc/virtual/2025/poster/116852) Â· [Project](https://neuroailab.github.io/opt_cwm_page/) |
| **Self-alignment of Large Video Language Models with Refined Regularized Preference Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/116821) Â· [Project](https://pritamsarkar.com/RRPO/) |
| **StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant** | [Paper](https://neurips.cc/virtual/2025/poster/119217) |
| **StreamForest: Efficient Online Video Understanding with Persistent Event Memory** | [Paper](https://neurips.cc/virtual/2025/poster/119513) Â· [GitHub](https://github.com/MCG-NJU/StreamForest) |
| **SuperCLIP: CLIP with Simple Classification Supervision** | [Paper](https://neurips.cc/virtual/2025/poster/119115) Â· [GitHub](https://github.com/hustvl/SuperCLIP) |
| **TAPVid-360: Tracking Any Point in 360 from Narrow Field of View Video** | [Paper](https://neurips.cc/virtual/2025/poster/121429) |
| **TC-Light: Temporally Coherent Generative Rendering for Realistic World Transfer** | [Paper](https://neurips.cc/virtual/2025/poster/117580) Â· [Project](https://dekuliutesla.github.io/tclight/) |
| **TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/118650) |
| **Taming generative video models for zero-shot optical flow extraction** | [Paper](https://neurips.cc/virtual/2025/poster/116626) Â· [Project](https://neuroailab.github.io/projects/kl_tracing/) |
| **TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/115934) |
| **Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames** | [Paper](https://neurips.cc/virtual/2025/poster/119395) |
| **Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/116757) Â· [Project](https://xuboshen.github.io/Time-R1/) |
| **Towards Understanding Camera Motions in Any Video** | [Paper](https://neurips.cc/virtual/2025/poster/121600) |
| **Tracking and Understanding Object Transformations** | [Paper](https://neurips.cc/virtual/2025/poster/116782) Â· [Project](https://tubelet-graph.github.io/) |
| **Training-free Online Video Step Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/116701) Â· [Project](https://lucazanella.github.io/baglm/) |
| **Two Causally Related Needles in a Video Haystack** | [Paper](https://neurips.cc/virtual/2025/poster/121468) Â· [Project](https://limiaoyu.github.io/Causal2Needles/) |
| **Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Video Temporal Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/118007) Â· [Project](https://lwpyh.github.io/URPA/) |
| **UniViT: Unifying Image and Video Understanding in One Vision Encoder** | [Paper](https://neurips.cc/virtual/2025/poster/118396) |
| **Universal Video Temporal Grounding with Generative Multi-modal Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/119042) Â· [Project](https://lzq5.github.io/UniTime/) |
| **Unleashing Hour-Scale Video Training for Long Video-Language Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/120098) Â· [Project](https://videomarathon.github.io/) |
| **Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/119064) Â· [GitHub](https://github.com/zaiquanyang/LLaVA_Next_STVG) |
| **VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations** | [Paper](https://neurips.cc/virtual/2025/poster/121556) |
| **VIBE: Annotation-Free Video-to-Text Information Bottleneck Evaluation for TL;DR** | [Paper](https://neurips.cc/virtual/2025/poster/119324) Â· [Project](https://vivianchen98.github.io/VIBE_website/) |
| **VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction** | [Paper](https://neurips.cc/virtual/2025/poster/119619) Â· [GitHub](https://github.com/VITA-MLLM/VITA) |
| **VITRIX-CLIPIN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction-Editing Data and Long Captions** | [Paper](https://neurips.cc/virtual/2025/poster/118953) Â· [Project](https://tommmmywangzt1118.github.io/VITRIX-CLIPIN/) |
| **Vad-R1: Towards Video Anomaly Reasoning via Perception-to-Cognition Chain-of-Thought** | [Paper](https://neurips.cc/virtual/2025/poster/119777) |
| **Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/119823) Â· [Project](https://xiaoqian-shen.github.io/Vgent/) |
| **VidEmo: Affective-Tree Reasoning for Emotion-Centric Video Foundation Models** | [Paper](https://neurips.cc/virtual/2025/poster/115267) |
| **Video Perception Models for 3D Scene Synthesis** | [Paper](https://neurips.cc/virtual/2025/poster/119253) Â· [Project](https://vipscene.github.io/) |
| **Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension** | [Paper](https://neurips.cc/virtual/2025/poster/118120) Â· [Project](https://video-rag.github.io/) |
| **VideoGameQA-Bench: Evaluating Vision-Language Models for Video Game Quality Assurance** | [Paper](https://neurips.cc/virtual/2025/poster/121740) |
| **VideoHallu: Evaluating and Mitigating Multi-modal Hallucinations on Synthetic Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/118334) |
| **VideoLucy: Deep Memory Backtracking for Long Video Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/117816) Â· [Project](https://videolucy.github.io/) |
| **VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/119996) |
| **VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/120298) Â· [Project](https://walkermitty.github.io/VimoRAG/) |
| **When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions** | [Paper](https://neurips.cc/virtual/2025/poster/118798) Â· [GitHub](https://github.com/Zhuo-Cao/QV-M2) |
| **When Thinking Drifts: Evidential Grounding for Robust Video Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/115892) |
| **Where Does It Exist from the Low-Altitude: Spatial Aerial Video Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/116334) Â· [GitHub](https://github.com/ZhanYang-nwpu/SAVG) |
| **WorldModelBench: Judging Video Generation Models As World Models** | [Paper](https://neurips.cc/virtual/2025/poster/121570) Â· [Project](https://worldmodelbench-team.github.io/) |
| **iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/116305) |

## ğŸ‘ï¸ Perception & Grounding

| Paper | Links |
|-------|-------|
| **Accelerating Multimodal Large Language Models via Dynamic Visual-Token Exit and the Empirical Findings** | [Paper](https://neurips.cc/virtual/2025/poster/118110) |
| **Adaptive Re-calibration Learning for Balanced Multimodal Intention Recognition** | [Paper](https://neurips.cc/virtual/2025/poster/116409) |
| **Aha! - Predicting What Matters Next: Online Highlight Detection Without Looking Ahead** | [Paper](https://neurips.cc/virtual/2025/poster/119707) Â· [arXiv](https://arxiv.org/abs/2509.16421) |
| **Attention! Your Vision Language Model Could Be Maliciously Manipulated** | [Paper](https://neurips.cc/virtual/2025/poster/119984) Â· [GitHub](https://github.com/Trustworthy-AI-Group/VMA) |
| **ChA-MAEViT: Unifying Channel-Aware Masked Autoencoders and Multi-Channel Vision Transformers for Improved Cross-Channel Learning** | [Paper](https://neurips.cc/virtual/2025/poster/118668) |
| **CoFFT: Chain of Foresight-Focus Thought for Visual Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/119460) |
| **ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts** | [Paper](https://neurips.cc/virtual/2025/poster/117275) Â· [GitHub](https://github.com/Linfeng-Tang/ControlFusion) |
| **Cross-modal Associations in Vision and Language Models: Revisiting the Bouba-Kiki Effect** | [Paper](https://neurips.cc/virtual/2025/poster/116707) |
| **Don't Just Chase â€œHighlighted Tokensâ€ in MLLMs: Revisiting Visual Holistic Context Retention** | [Paper](https://neurips.cc/virtual/2025/poster/115059) Â· [GitHub](https://github.com/obananas/HoloV) |
| **EOC-Bench: Can MLLMs Identify, Recall, and Forecast Objects in an Egocentric World?** | [Paper](https://neurips.cc/virtual/2025/poster/121637) Â· [Project](https://circleradon.github.io/EOCBench/) |
| **EgoBlind: Towards Egocentric Visual Assistance for the Blind** | [Paper](https://neurips.cc/virtual/2025/poster/121565) |
| **End-to-End Vision Tokenizer Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/116026) |
| **Enhancing Vision-Language Model Reliability with Uncertainty-Guided Dropout Decoding** | [Paper](https://neurips.cc/virtual/2025/poster/118572) Â· [GitHub](https://github.com/kigb/DropoutDecoding) |
| **FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts** | [Paper](https://neurips.cc/virtual/2025/poster/119165) |
| **Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling** | [Paper](https://neurips.cc/virtual/2025/poster/117369) Â· [GitHub](https://github.com/bryanwong17/HiVE-MIL) |
| **Find your Needle: Small Object Image Retrieval via Multi-Object Attention Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/116342) Â· [Project](https://pihash2k.github.io/findyourneedle.github.io/) |
| **FlySearch: Exploring how vision-language models explore** | [Paper](https://neurips.cc/virtual/2025/poster/121733) Â· [Project](https://flysearch.gmum.net/) |
| **GUIDED: Granular Understanding via Identification, Detection, and Discrimination for Fine-Grained Open-Vocabulary Object Detection** | [Paper](https://neurips.cc/virtual/2025/poster/118040) |
| **INST-IT: Boosting Instance Understanding via Explicit Visual Prompt Instruction Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/119587) Â· [Project](https://inst-it.github.io/) |
| **LISAt: Language-Instructed Segmentation Assistant for Satellite Imagery** | [Paper](https://neurips.cc/virtual/2025/poster/121596) Â· [Project](https://lisat-bair.github.io/LISAt/) |
| **LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation** | [Paper](https://neurips.cc/virtual/2025/poster/115443) |
| **MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification** | [Paper](https://neurips.cc/virtual/2025/poster/119678) Â· [GitHub](https://github.com/stone96123/MDReID) |
| **Native Segmentation Vision Transformers** | [Paper](https://neurips.cc/virtual/2025/poster/117718) Â· [Project](https://research.nvidia.com/labs/dvl/projects/native-segmentation/) |
| **NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception** | [Paper](https://neurips.cc/virtual/2025/poster/119565) |
| **Object-centric binding in Contrastive Language-Image Pretraining** | [Paper](https://neurips.cc/virtual/2025/poster/116977) |
| **On the rankability of visual embeddings** | [Paper](https://neurips.cc/virtual/2025/poster/115697) |
| **Perception Encoder: The best visual embeddings are not at the output of the network** | [Paper](https://neurips.cc/virtual/2025/poster/118805) |
| **PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/119876) Â· [GitHub](https://github.com/facebookresearch/perception_models) |
| **Prioritizing Perception-Guided Self-Supervision: A New Paradigm for Causal Modeling in End-to-End Autonomous Driving** | [Paper](https://neurips.cc/virtual/2025/poster/118209) |
| **Q-Insight: Understanding Image Quality via Visual Reinforcement Learning** | [Paper](https://neurips.cc/virtual/2025/poster/119363) Â· [GitHub](https://github.com/bytedance/Q-Insight) |
| **REOrdering Patches Improves Vision Models** | [Paper](https://neurips.cc/virtual/2025/poster/116773) |
| **RESAnything: Attribute Prompting for Arbitrary Referring Segmentation** | [Paper](https://neurips.cc/virtual/2025/poster/119834) |
| **SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing** | [Paper](https://neurips.cc/virtual/2025/poster/115001) |
| **SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation** | [Paper](https://neurips.cc/virtual/2025/poster/117451) Â· [Project](https://zhenjiemao.github.io/SaFiRe/) |
| **Seeking and Updating with Live Visual Knowledge** | [Paper](https://neurips.cc/virtual/2025/poster/121414) Â· [Project](https://livevqa.github.io/) |
| **ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/120248) Â· [Project](https://vchitect.github.io/ShotBench-project/) |
| **Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence** | [Paper](https://neurips.cc/virtual/2025/poster/117993) Â· [Project](https://diankun-wu.github.io/Spatial-MLLM/) |
| **Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation** | [Paper](https://neurips.cc/virtual/2025/poster/119296) Â· [GitHub](https://github.com/dosowiechi/MLMP) |
| **Test-Time Adaptive Object Detection with Foundation Model** | [Paper](https://neurips.cc/virtual/2025/poster/118473) |
| **Towards General Continuous Memory for Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/117409) |
| **Towards Reliable and Holistic Visual In-Context Learning Prompt Selection** | [Paper](https://neurips.cc/virtual/2025/poster/119157) |
| **Towards Self-Refinement of Vision-Language Models with Triangular Consistency** | [Paper](https://neurips.cc/virtual/2025/poster/118260) |
| **Unified Reinforcement and Imitation Learning for Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/119665) Â· [Project](https://byungkwanlee.github.io/RIL-page/) |
| **VITRIX-UniViTAR: Unified Vision Transformer with Native Resolution** | [Paper](https://neurips.cc/virtual/2025/poster/118217) |
| **VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning** | [Paper](https://neurips.cc/virtual/2025/poster/119918) Â· [Project](https://tiger-ai-lab.github.io/VL-Rethinker/) |
| **VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set** | [Paper](https://neurips.cc/virtual/2025/poster/120232) Â· [GitHub](https://github.com/ssfgunner/VL-SAE) |
| **VL-SAM-V2: Open-World Object Detection with General and Specific Query Fusion** | [Paper](https://neurips.cc/virtual/2025/poster/118607) |
| **VaMP: Variational Multi-Modal Prompt Learning for Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/119603) Â· [Project](https://visual-ai.github.io/vamp) |
| **ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs** | [Paper](https://neurips.cc/virtual/2025/poster/116500) |
| **ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding** | [Paper](https://neurips.cc/virtual/2025/poster/115277) Â· [GitHub](https://github.com/KangJialiang/ViSpec) |
| **Vision Function Layer in Multimodal LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/116134) |
| **Vision Transformers with Self-Distilled Registers** | [Paper](https://neurips.cc/virtual/2025/poster/117648) |
| **VisualLens: Personalization through Task-Agnostic Visual History** | [Paper](https://neurips.cc/virtual/2025/poster/119005) |
| **Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM** | [Paper](https://neurips.cc/virtual/2025/poster/116376) |

## ğŸ“Š Benchmarks & Evaluation

| Paper | Links |
|-------|-------|
| **CAPability: A Comprehensive Visual Caption Benchmark for Evaluating Both Correctness and Thoroughness** | [Paper](https://neurips.cc/virtual/2025/poster/121398) Â· [Project](https://capability-bench.github.io/) |
| **CHOICE: Benchmarking the Remote Sensing Capabilities of Large Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121749) Â· [GitHub](https://github.com/ShawnAn-WHU/CHOICE) Â· [Project](https://rs-choice.github.io/) |
| **Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark** | [Paper](https://neurips.cc/virtual/2025/poster/121723) Â· [GitHub](https://github.com/thuiar/MMLA) |
| **Counterfactual Evolution of Multimodal Datasets via Visual Programming** | [Paper](https://neurips.cc/virtual/2025/poster/117179) |
| **CrypticBio: A Large Multimodal Dataset for Visually Confusing Species** | [Paper](https://neurips.cc/virtual/2025/poster/121654) Â· [Project](https://georgianagmanolache.github.io/crypticbio) |
| **DAVE: Diagnostic benchmark for Audio Visual Evaluation** | [Paper](https://neurips.cc/virtual/2025/poster/121842) Â· [GitHub](https://github.com/gorjanradevski/dave) |
| **DisasterM3: A Remote Sensing Vision-Language Dataset for Disaster Damage Assessment and Response** | [Paper](https://neurips.cc/virtual/2025/poster/121427) Â· [GitHub](https://github.com/Junjue-Wang/DisasterM3) |
| **DynamicVL: Benchmarking Multimodal Large Language Models for Dynamic City Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121371) Â· [GitHub](https://github.com/weihao1115/dynamicvl) |
| **EgoExOR: An Ego-Exo-Centric  Operating Room Dataset for Surgical Activity Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121697) Â· [GitHub](https://github.com/ardamamur/EgoExOR) |
| **Enhancing Infrared Vision: Progressive Prompt Fusion Network and Benchmark** | [Paper](https://neurips.cc/virtual/2025/poster/115172) |
| **Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere** | [Paper](https://neurips.cc/virtual/2025/poster/116582) Â· [GitHub](https://github.com/li-ju666/asymvlm) |
| **Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants** | [Paper](https://neurips.cc/virtual/2025/poster/121722) Â· [Project](https://face-human-bench.github.io/) |
| **Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/121686) Â· [GitHub](https://github.com/AIF4S/Hyperphantasia) |
| **IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants** | [Paper](https://neurips.cc/virtual/2025/poster/121501) Â· [Project](https://indego-dataset.github.io/) |
| **InfoChartQA: A Benchmark for Multimodal Question Answering on Infographic Charts** | [Paper](https://neurips.cc/virtual/2025/poster/121377) Â· [GitHub](https://github.com/thu-vis/InfoChartQA) |
| **MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121773) Â· [GitHub](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) |
| **MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly** | [Paper](https://neurips.cc/virtual/2025/poster/121768) Â· [Project](https://zhaowei-wang-nlp.github.io/MMLongBench-page/) |
| **RGB-to-Polarization Estimation: A New Task and Benchmark Study** | [Paper](https://neurips.cc/virtual/2025/poster/121777) |
| **RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events** | [Paper](https://neurips.cc/virtual/2025/poster/121378) Â· [Project](https://bili-sakura.github.io/RSCC/) |
| **Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121741) Â· [Project](https://rf100-vl.org/) |
| **TaiwanVQA: Benchmarking and Enhancing Cultural Understanding in Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121559) Â· [Project](https://huggingface.co/datasets/hhhuang/TaiwanVQA) |
| **V2X-Radar: A Multi-modal Dataset with 4D Radar for Cooperative Perception** | [Paper](https://neurips.cc/virtual/2025/poster/121426) Â· [GitHub](https://github.com/yanglei18/V2X-Radar) |
| **WearVQA: A Visual Question Answering Benchmark for Wearables in Egocentric Authentic Real-world scenarios** | [Paper](https://neurips.cc/virtual/2025/poster/121428) |

## ğŸ”„ Multimodal Alignment & Pre-training

| Paper | Links |
|-------|-------|
| **Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment** | [Paper](https://neurips.cc/virtual/2025/poster/118266) |
| **Amplifying Prominent Representations in Multimodal Learning  via Variational Dirichlet Process** | [Paper](https://neurips.cc/virtual/2025/poster/117022) |
| **Automatic Synthetic Data and Fine-grained Adaptive Feature Alignment for Composed Person Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/115728) Â· [GitHub](https://github.com/Delong-liu-bupt/Composed_Person_Retrieval) |
| **Continual Multimodal Contrastive Learning** | [Paper](https://neurips.cc/virtual/2025/poster/116428) |
| **GRIT: Teaching MLLMs to Think with Images** | [Paper](https://neurips.cc/virtual/2025/poster/118020) Â· [Project](https://grounded-reasoning.github.io/) |
| **Gaze-VLM: Bridging Gaze and VLMs through Attention Regularization for Egocentric Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/120280) |
| **Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment** | [Paper](https://neurips.cc/virtual/2025/poster/116450) |
| **MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models** | [Paper](https://neurips.cc/virtual/2025/poster/121711) |
| **MokA: Multimodal Low-Rank Adaptation for MLLMs** | [Paper](https://neurips.cc/virtual/2025/poster/116047) Â· [Project](https://gewu-lab.github.io/MokA/) |
| **Neighbor-aware Contrastive Disambiguation for Cross-Modal Hashing with Redundant Annotations** | [Paper](https://neurips.cc/virtual/2025/poster/136220) Â· [GitHub](https://github.com/Rose-bud/NACD) |
| **SpaceServe: Spatial Multiplexing of Complementary Encoders and Decoders for Multimodal LLMs** | [Paper](https://neurips.cc/virtual/2025/poster/115356) Â· [GitHub](https://github.com/gofreelee/SpaceServe) |
| **With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You** | [Paper](https://neurips.cc/virtual/2025/poster/118769) Â· [Project](https://brbiclab.epfl.ch/projects/structure/) |
| **Zooming from Context to Cue: Hierarchical Preference Optimization for Multi-Image MLLMs** | [Paper](https://neurips.cc/virtual/2025/poster/116709) |

## ğŸ–¼ï¸ Generation & Editing

| Paper | Links |
|-------|-------|
| **Benchmarking Retrieval-Augmented Multimomal Generation for Document Question Answering** | [Paper](https://neurips.cc/virtual/2025/poster/121603) Â· [Project](https://mmdocrag.github.io/MMDocRAG/) |
| **Co-Reinforcement Learning for Unified Multimodal Understanding and Generation** | [Paper](https://neurips.cc/virtual/2025/poster/117287) |
| **DGSolver: Diffusion Generalist Solver with Universal Posterior Sampling for Image Restoration** | [Paper](https://neurips.cc/virtual/2025/poster/116716) Â· [GitHub](https://github.com/MiliLab/DGSolver) |
| **DPÂ²O-SR: Direct Perceptual Preference Optimization for Real-World Image Super-Resolution** | [Paper](https://neurips.cc/virtual/2025/poster/119975) Â· [GitHub](https://github.com/cswry/DP2O-SR) |
| **Enhancing Text-to-Image Diffusion Transformer via Split-Text Conditioning** | [Paper](https://neurips.cc/virtual/2025/poster/120085) Â· [GitHub](https://github.com/zy-ansel/DiT-ST) |
| **HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation** | [Paper](https://neurips.cc/virtual/2025/poster/118982) Â· [GitHub](https://github.com/Gen-Verse/HermesFlow) |
| **LEDiT:  Your Length-Extrapolatable Diffusion Transformer without Positional Encoding** | [Paper](https://neurips.cc/virtual/2025/poster/119583) |
| **LaViDa: A Large Diffusion Model for Vision-Language Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/119782) |
| **MMaDA: Multimodal Large Diffusion Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/115311) Â· [GitHub](https://github.com/Gen-Verse/MMaDA) |
| **Personalized Visual Content Generation in Conversational Systems** | [Paper](https://neurips.cc/virtual/2025/poster/119795) |
| **Promptable 3-D Object Localization with Latent Diffusion Models** | [Paper](https://neurips.cc/virtual/2025/poster/119053) |
| **Rare Text Semantics Were Always There in Your Diffusion Transformer** | [Paper](https://neurips.cc/virtual/2025/poster/115559) |
| **Reliable Lifelong Multimodal Editing: Conflict-Aware Retrieval Meets Multi-Level Guidance** | [Paper](https://neurips.cc/virtual/2025/poster/116635) |
| **Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/120302) Â· [GitHub](https://github.com/newLLing/Table2LaTeX-RL) |
| **UniGen: Enhanced Training & Test-Time Strategies for Unified Multimodal Understanding and Generation** | [Paper](https://neurips.cc/virtual/2025/poster/116520) |
| **UniTok: a Unified Tokenizer for Visual Generation and Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/116864) Â· [Project](https://foundationvision.github.io/UniTok/) |
| **Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations** | [Paper](https://neurips.cc/virtual/2025/poster/118811) Â· [Project](https://tar.csuhan.com/) |

## ğŸ›¡ï¸ Safety, Trustworthiness & Hallucination

| Paper | Links |
|-------|-------|
| **A Frustratingly Simple Yet Highly Effective Attack Baseline: Over 90% Success Rate Against the Strong Black-box Models of GPT-4.5/4o/o1** | [Paper](https://neurips.cc/virtual/2025/poster/119497) Â· [GitHub](https://github.com/VILA-Lab/M-Attack) |
| **Decoupling Contrastive Decoding: Robust Hallucination Mitigation in Multimodal Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/118235) |
| **Directed-Tokens: A Robust Multi-Modality Alignment Approach to Large Language-Vision Models** | [Paper](https://neurips.cc/virtual/2025/poster/116581) |
| **Discovering Compositional Hallucinations in LVLMs** | [Paper](https://neurips.cc/virtual/2025/poster/119442) |
| **Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling** | [Paper](https://neurips.cc/virtual/2025/poster/120029) Â· [Project](https://reverse-vlm.github.io/) |
| **Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning** | [Paper](https://neurips.cc/virtual/2025/poster/115500) |
| **Image Token Matters: Mitigating Hallucination in Discrete Tokenizer-based Large Vision-Language Models via Latent Editing** | [Paper](https://neurips.cc/virtual/2025/poster/117602) |
| **Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats** | [Paper](https://neurips.cc/virtual/2025/poster/118894) Â· [GitHub](https://github.com/SooLab/AllPath) |
| **Languageâ€‘Biasâ€‘Resilient Visual Question Answering via Adaptive Multiâ€‘Margin Collaborative Debiasing** | [Paper](https://neurips.cc/virtual/2025/poster/115795) |
| **Miss-ReID: Delivering Robust Multi-Modality Object Re-Identification Despite Missing Modalities** | [Paper](https://neurips.cc/virtual/2025/poster/119663) |
| **Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/115608) Â· [GitHub](https://github.com/Liuwq-bit/SymMPO) |
| **On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/116514) Â· [Project](https://keenyjin.github.io/epistemic/) |
| **Partition-Then-Adapt: Combating Prediction Bias for Reliable Multi-Modal Test-Time Adaptation** | [Paper](https://neurips.cc/virtual/2025/poster/117876) Â· [GitHub](https://github.com/MPI-Lab/PTA) |
| **Poison as Cure: Visual Noise for Mitigating Object Hallucinations in LVMs** | [Paper](https://neurips.cc/virtual/2025/poster/115828) Â· [Project](https://kejiazhang-robust.github.io/poison-cure-lvm) |
| **Projection-Manifold Regularized Latent Diffusion for Robust General Image Fusion** | [Paper](https://neurips.cc/virtual/2025/poster/117987) |
| **Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets** | [Paper](https://neurips.cc/virtual/2025/poster/117085) |
| **Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization** | [Paper](https://neurips.cc/virtual/2025/poster/118212) Â· [GitHub](https://github.com/CuriseJia/NeurIPS2025-Spotlight-SSHS) |
| **Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/117155) |
| **Systematic Reward Gap Optimization for Mitigating VLM Hallucinations** | [Paper](https://neurips.cc/virtual/2025/poster/116851) Â· [Project](https://tpr-dpo.github.io/) |
| **Towards Robust Uncertainty Calibration for Composed Image Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/118555) |
| **Understanding and Rectifying Safety Perception Distortion in VLMs** | [Paper](https://neurips.cc/virtual/2025/poster/118667) |

## ğŸ¤– Embodied AI & Robotics

| Paper | Links |
|-------|-------|
| **BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent** | [Paper](https://neurips.cc/virtual/2025/poster/119419) |
| **Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents** | [Paper](https://neurips.cc/virtual/2025/poster/121655) Â· [Project](https://facebookresearch.github.io/WAGIBench/) |
| **Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence** | [Paper](https://neurips.cc/virtual/2025/poster/121809) Â· [Project](https://embodied-web-agent.github.io/) |
| **GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation** | [Paper](https://neurips.cc/virtual/2025/poster/117425) Â· [Project](https://leon022.github.io/GUI-Rise/) |
| **Hierarchical Semantic-Augmented Navigation: Optimal Transport and Graph-Driven Reasoning for Vision-Language Navigation** | [Paper](https://neurips.cc/virtual/2025/poster/115108) |
| **Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/115154) Â· [Project](https://neurips.cc/virtual/2025/loc/san-diego/poster/sport-agents.github.io) |
| **MIP against Agent: Malicious Image Patches Hijacking Multimodal OS Agents** | [Paper](https://neurips.cc/virtual/2025/poster/117813) Â· [Project](https://neurips.cc/virtual/2025/loc/san-diego/poster/aichberger.github.io) |
| **Perception-R1: Pioneering Perception Policy with Reinforcement Learning** | [Paper](https://neurips.cc/virtual/2025/poster/119361) Â· [arXiv](https://arxiv.org/pdf/2504.07954) |
| **RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics** | [Paper](https://neurips.cc/virtual/2025/poster/118306) Â· [Project](https://zhoues.github.io/RoboRefer/) |
| **STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/115370) |
| **Semi-off-Policy Reinforcement Learning for Vision-Language Slow-Thinking Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/115068) |
| **Towards Unified Multimodal Interleaved Generation via Group Relative Policy Optimization** | [Paper](https://neurips.cc/virtual/2025/poster/116276) |
| **UI-Genie: A Self-Improving Approach for Iteratively Boosting MLLM-based Mobile GUI Agents** | [Paper](https://neurips.cc/virtual/2025/poster/119990) |

## ğŸ§Š 3D & Point Clouds

| Paper | Links |
|-------|-------|
| **3EED: Ground Everything Everywhere in 3D** | [Paper](https://neurips.cc/virtual/2025/poster/121462) Â· [Project](https://project-3eed.github.io/) |
| **AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/118403) |
| **Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning** | [Paper](https://neurips.cc/virtual/2025/poster/119465) Â· [GitHub](https://github.com/RFLeijenaar/AsymDSD) |
| **Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment** | [Paper](https://neurips.cc/virtual/2025/poster/115767) Â· [Project](https://aim-skku.github.io/ADAPT/) |
| **CroPe: Cross-Modal Semantic Compensation Adaptation for All Adverse Scene Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/120067) Â· [GitHub](https://github.com/wqh011128/CroPe) |
| **DIFFSSR: Stereo Image Super-resolution Using Differential Transformer** | [Paper](https://neurips.cc/virtual/2025/poster/115153) Â· [GitHub](https://github.com/Zdafeng/DIFFSSR) |
| **Distil-E2D: Distilling Image-to-Depth Priors for Event-Based Monocular Depth Estimation** | [Paper](https://neurips.cc/virtual/2025/poster/115168) |
| **Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation** | [Paper](https://neurips.cc/virtual/2025/poster/115715) |
| **ESCA: Contextualizing Embodied Agents via Scene-Graph Generation** | [Paper](https://neurips.cc/virtual/2025/poster/117064) |
| **From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes** | [Paper](https://neurips.cc/virtual/2025/poster/121709) Â· [Project](https://anywhere-3d.github.io/) |
| **Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span** | [Paper](https://neurips.cc/virtual/2025/poster/119590) |
| **IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals** | [Paper](https://neurips.cc/virtual/2025/poster/117455) Â· [Project](https://markus-42.github.io/publications/2025/ipformer/) |
| **IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering** | [Paper](https://neurips.cc/virtual/2025/poster/121555) Â· [Project](https://ir3d-bench.github.io/) |
| **Interactive Cross-modal Learning for Text-3D Scene Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/116802) |
| **MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance Generation** | [Paper](https://neurips.cc/virtual/2025/poster/116050) |
| **MLLM-ISU: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models based Intrusion Scene Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121848) Â· [GitHub](https://github.com/1012537710/MLLM-ISU) |
| **MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling** | [Paper](https://neurips.cc/virtual/2025/poster/118782) Â· [GitHub](https://github.com/yingift/MSTAR) |
| **NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/118147) Â· [GitHub](https://github.com/H-EmbodVis/NAUTILUS) |
| **OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects** | [Paper](https://neurips.cc/virtual/2025/poster/117447) Â· [Project](https://markhh.com/OnlineSplatter/) |
| **OpenBox: Annotate Any Bounding Boxes in 3D** | [Paper](https://neurips.cc/virtual/2025/poster/119679) |
| **OpenHype: Hyperbolic Embeddings for Hierarchical Open-Vocabulary Radiance Fields** | [Paper](https://neurips.cc/virtual/2025/poster/115048) Â· [Project](https://lisaweijler.github.io/openhype-projectpage/) |
| **Robust Cross-modal Alignment Learning for Cross-Scene Spatial Reasoning and Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/115216) |
| **SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/118216) Â· [Project](https://cpystan.github.io/SD_VLM_pages/) |
| **SceneForge: Enhancing 3D-text alignment with Structured Scene Compositions** | [Paper](https://neurips.cc/virtual/2025/poster/119379) Â· [Project](https://mortorit.github.io/sceneforge-neurips2025/) |
| **SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent** | [Paper](https://neurips.cc/virtual/2025/poster/115278) Â· [Project](https://scene-weaver.github.io/) |
| **Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model** | [Paper](https://neurips.cc/virtual/2025/poster/121602) |
| **SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/116669) Â· [Project](https://spatial-reasoner.github.io/) |
| **Towards 3D Objectness Learning in an Open World** | [Paper](https://neurips.cc/virtual/2025/poster/115346) Â· [Project](https://op3det.github.io/) |
| **Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs** | [Paper](https://neurips.cc/virtual/2025/poster/116235) Â· [GitHub](https://github.com/Leeinsu1/Towards-Comprehensive-Scene-Understanding) |
| **VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting** | [Paper](https://neurips.cc/virtual/2025/poster/118352) |
| **ViSPLA: Visual Iterative Self-Prompting for Language-Guided 3D Affordance Learning** | [Paper](https://neurips.cc/virtual/2025/poster/119081) Â· [Project](https://hritam-98.github.io/VisPLA/) |
| **Walking the SchrÃ¶dinger Bridge: A Direct Trajectory for Text-to-3D Generation** | [Paper](https://neurips.cc/virtual/2025/poster/116147) Â· [GitHub](https://github.com/emmaleee789/TraCe.git) |
| **Whatâ€™s in Common? Multimodal Models Hallucinate When Reasoning Across Scenes** | [Paper](https://neurips.cc/virtual/2025/poster/121545) |
| **When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/119366) |

## ğŸ§  Reasoning & Chain-of-Thought

| Paper | Links |
|-------|-------|
| **A2Seek: Towards Reasoning-Centric Benchmark for Aerial Anomaly Understanding** | [Paper](https://neurips.cc/virtual/2025/poster/121562) Â· [Project](https://2-mo.github.io/A2Seek) |
| **Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/116431) |
| **ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121447) Â· [GitHub](https://github.com/Liyan06/ChartMuseum) Â· [Project](https://chartmuseum-leaderboard.github.io/) |
| **ColorBench: Can VLMs See and Understand the Colorful World? A Comprehensive Benchmark for Color Perception, Reasoning, and Robustness** | [Paper](https://neurips.cc/virtual/2025/poster/121433) |
| **EvolvedGRPO: Unlocking Reasoning in LVLMs via Progressive Instruction Evolution** | [Paper](https://neurips.cc/virtual/2025/poster/115560) Â· [GitHub](https://github.com/SHENZHEBEI/EvolvedGRPO) |
| **Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs** | [Paper](https://neurips.cc/virtual/2025/poster/118573) Â· [Project](https://plan-lab.github.io/spatialreasoner) |
| **First SFT, Second RL, Third UPT: Continual Improving Multi-Modal LLM Reasoning via Unsupervised Post-Training** | [Paper](https://neurips.cc/virtual/2025/poster/118898) Â· [GitHub](https://github.com/waltonfuture/MM-UPT) |
| **FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/118495) Â· [GitHub](https://github.com/TungChintao/FlowCut) |
| **GRE Suite: Geo-localization Inference via Fine-Tuned Vision-Language Models and Enhanced Reasoning Chains** | [Paper](https://neurips.cc/virtual/2025/poster/119959) |
| **Grounded Reinforcement Learning for Visual Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/120218) Â· [Project](https://visually-grounded-rl.github.io/) |
| **HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/117109) Â· [Project](https://ntumars.github.io/project/HoloLLM/) |
| **Knot So Simple: A Minimalistic Environment for Spatial Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/121700) Â· [Project](https://lil-lab.github.io/knotgym/) |
| **MINT-CoT: Enabling Interleaved Visual Tokens in Mathematical Chain-of-Thought Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/115416) Â· [GitHub](https://github.com/xinyan-cxy/MINT-CoT) |
| **MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations** | [Paper](https://neurips.cc/virtual/2025/poster/121750) Â· [Project](https://mirage-benchmark.github.io/) |
| **MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121826) Â· [GitHub](https://github.com/MM-OPERA-Bench/MM-OPERA) |
| **MMMG: A Massive, Multidisciplinary, Multi-Tier Generation Benchmark for Text-to-Image Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/121491) Â· [Project](https://mmmgbench.github.io/) |
| **MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness** | [Paper](https://neurips.cc/virtual/2025/poster/121606) Â· [Project](https://yunlong10.github.io/MMPerspective/) |
| **MiCo: Multi-image Contrast for Reinforcement Visual Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/117848) |
| **MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO** | [Paper](https://neurips.cc/virtual/2025/poster/118384) Â· [GitHub](https://github.com/TencentARC/MindOmni) |
| **More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models** | [Paper](https://neurips.cc/virtual/2025/poster/118585) Â· [Project](https://mlrm-halu.github.io/) |
| **Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search** | [Paper](https://neurips.cc/virtual/2025/poster/116245) Â· [GitHub](https://github.com/HJYao00/Mulberry/tree/main) |
| **Multi-step Visual Reasoning with Visual Tokens Scaling and Verification** | [Paper](https://neurips.cc/virtual/2025/poster/115184) |
| **Multimodal Causal Reasoning for UAV Object Detection** | [Paper](https://neurips.cc/virtual/2025/poster/118849) |
| **NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation** | [Paper](https://neurips.cc/virtual/2025/poster/115801) Â· [Project](https://artanic30.github.io/project_pages/NoisyGRPO/) |
| **OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/121614) Â· [GitHub](https://github.com/Yuliang-Liu/MultimodalOCR) |
| **Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration** | [Paper](https://neurips.cc/virtual/2025/poster/119706) Â· [Project](https://aim-uofa.github.io/OmniR1/) |
| **R1-ShareVL: Incentivizing Reasoning Capabilities of Multimodal Large Language Models via Share-GRPO** | [Paper](https://neurips.cc/virtual/2025/poster/116391) Â· [GitHub](https://github.com/HJYao00/R1-ShareVL) |
| **Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/115287) Â· [GitHub](https://github.com/lingli1996/GLOBE) |
| **Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing** | [Paper](https://neurips.cc/virtual/2025/poster/115095) Â· [GitHub](https://github.com/AntResearchNLP/ViLaSR) |
| **Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion** | [Paper](https://neurips.cc/virtual/2025/poster/118166) |
| **Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/119582) |
| **SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning** | [Paper](https://neurips.cc/virtual/2025/poster/116679) Â· [Project](https://srpo.pages.dev/) |
| **SURDS: Benchmarking Spatial Understanding and Reasoning in Driving Scenarios with Vision Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121802) Â· [GitHub](https://github.com/xiandaguo/drive-mllm) |
| **SeePhys:  Does Seeing Help Thinking? â€“ Benchmarking Vision-Based Physics Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/121799) Â· [Project](https://seephys.github.io/) |
| **SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement** | [Paper](https://neurips.cc/virtual/2025/poster/118230) |
| **Struct2D: A Perception-Guided Framework for Spatial Reasoning in MLLMs** | [Paper](https://neurips.cc/virtual/2025/poster/115762) |
| **To Think or Not To Think: A Study of Thinking in Rule-Based Visual Reinforcement Fine-Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/117405) Â· [GitHub](https://github.com/minglllli/CLS-RL/tree/main) |
| **Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition** | [Paper](https://neurips.cc/virtual/2025/poster/116052) Â· [GitHub](https://github.com/BFlameSwift/Uni-MuMER) |
| **UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning** | [Paper](https://neurips.cc/virtual/2025/poster/120066) Â· [Project](https://polyu-chenlab.github.io/unipixel/) |
| **Unified Multimodal Chain-of-Thought Reward Model through Reinforcement Fine-Tuning** | [Paper](https://neurips.cc/virtual/2025/poster/117965) Â· [Project](https://codegoat24.github.io/UnifiedReward/think) |
| **Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards** | [Paper](https://neurips.cc/virtual/2025/poster/119237) Â· [GitHub](https://github.com/baaivision/CoS) |
| **Unveiling the Compositional Ability Gap in Vision-Language Reasoning Model** | [Paper](https://neurips.cc/virtual/2025/poster/118747) Â· [GitHub](https://github.com/ltl3A87/ComPA) |
| **VLM-RÂ³: Region Recognition, Reasoning, and Refinement for Enhanced Multimodal Chain-of-Thought** | [Paper](https://neurips.cc/virtual/2025/poster/119135) |
| **VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs** | [Paper](https://neurips.cc/virtual/2025/poster/117181) Â· [Project](https://vlmtunnel.github.io/) |
| **Visual Structures Help Visual Reasoning:  Addressing the Binding Problem in LVLMs** | [Paper](https://neurips.cc/virtual/2025/poster/117879) Â· [Project](https://sharif-ml-lab.github.io/VISER/) |
| **Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought** | [Paper](https://neurips.cc/virtual/2025/poster/115243) |
| **VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank** | [Paper](https://neurips.cc/virtual/2025/poster/115506) Â· [GitHub](https://github.com/TianheWu/VisualQuality-R1) |

## ğŸ©º Medical & Scientific

| Paper | Links |
|-------|-------|
| **ExGra-Med: Extended Context Graph Alignment for Medical Vision-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/117826) |
| **From Human Attention to Diagnosis: Semantic Patch-Level Integration of Vision-Language Models in Medical Imaging** | [Paper](https://neurips.cc/virtual/2025/poster/116279) |
| **MedSG-Bench: A Benchmark for Medical Image Sequences Grounding** | [Paper](https://neurips.cc/virtual/2025/poster/121815) Â· [GitHub](https://github.com/Yuejingkun/MedSG-Bench) |
| **Pancakes: Consistent Multi-Protocol Image Segmentation Across Biomedical Domains** | [Paper](https://neurips.cc/virtual/2025/poster/119522) |
| **Physics-informed Neural Operator for Pansharpening** | [Paper](https://neurips.cc/virtual/2025/poster/115598) |
| **RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Chest X-ray with Zero-Shot Multi-Task Capability** | [Paper](https://neurips.cc/virtual/2025/poster/117595) Â· [GitHub](https://github.com/deepnoid-ai/RadZero) |
| **SMMILE: An expert-driven benchmark for multimodal medical in-context learning** | [Paper](https://neurips.cc/virtual/2025/poster/121577) Â· [Project](https://smmile-benchmark.github.io/) |
| **THUNDER: Tile-level Histopathology image UNDERstanding benchmark** | [Paper](https://neurips.cc/virtual/2025/poster/121557) Â· [Project](https://mics-lab.github.io/thunder/) |
| **Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation** | [Paper](https://neurips.cc/virtual/2025/poster/121676) |
| **Towards Physics-informed Spatial Intelligence with Human Priors: An Autonomous Driving Pilot Study** | [Paper](https://neurips.cc/virtual/2025/poster/115976) Â· [Project](https://guanlinwu123.github.io/sigbench/) |

## ğŸ“š Other VLM Papers

| Paper | Links |
|-------|-------|
| **ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources** | [Paper](https://neurips.cc/virtual/2025/poster/115905) |
| **Automated Model Discovery via Multi-modal & Multi-step Pipeline** | [Paper](https://neurips.cc/virtual/2025/poster/115887) Â· [Project](https://mok0102.github.io/model-discovery/) |
| **Availability-aware Sensor Fusion via Unified Canonical Space** | [Paper](https://neurips.cc/virtual/2025/poster/116801) Â· [GitHub](https://github.com/kaist-avelab/K-Radar) |
| **Balancing Multimodal Training Through Game-Theoretic Regularization** | [Paper](https://neurips.cc/virtual/2025/poster/117227) Â· [GitHub](https://github.com/kkontras/MCR/tree/main) |
| **CAT: Content-Adaptive Image Tokenization** | [Paper](https://neurips.cc/virtual/2025/poster/117055) |
| **CMoB: Modality Valuation via Causal Effect for Balanced Multimodal Learning** | [Paper](https://neurips.cc/virtual/2025/poster/115120) |
| **Correlated Low-Rank Adaptation for ConvNets** | [Paper](https://neurips.cc/virtual/2025/poster/119997) Â· [GitHub](https://github.com/VISION-SJTU/CoLoRA) |
| **Elastic ViTs from Pretrained Models without Retraining** | [Paper](https://neurips.cc/virtual/2025/poster/118288) |
| **FRN: Fractal-Based Recursive Spectral Reconstruction Network** | [Paper](https://neurips.cc/virtual/2025/poster/119659) |
| **Hierarchical Information Aggregation for Incomplete Multimodal Alzheimer's Disease Diagnosis** | [Paper](https://neurips.cc/virtual/2025/poster/118245) |
| **Highlighting What Matters: Promptable Embeddings for Attribute-Focused Image Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/116759) |
| **Instance-Level Composed Image Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/119710) Â· [Project](https://vrg.fel.cvut.cz/icir/) |
| **InstructRestore: Region-Customized Image Restoration with Human Instructions** | [Paper](https://neurips.cc/virtual/2025/poster/115458) |
| **Learning Source-Free Domain Adaptation for Visible-Infrared Person Re-Identification** | [Paper](https://neurips.cc/virtual/2025/poster/118848) |
| **MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning** | [Paper](https://neurips.cc/virtual/2025/poster/117075) |
| **MERIT: Multilingual Semantic Retrieval with Interleaved Multi-Condition Query** | [Paper](https://neurips.cc/virtual/2025/poster/117050) Â· [Project](https://merit-2025.github.io/) |
| **MMPB: Itâ€™s Time for Multi-Modal Personalization** | [Paper](https://neurips.cc/virtual/2025/poster/121766) |
| **MONITRS: Multimodal Observations of Natural Incidents Through Remote Sensing** | [Paper](https://neurips.cc/virtual/2025/poster/121588) |
| **Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models** | [Paper](https://neurips.cc/virtual/2025/poster/119308) |
| **MixSignGraph: A Sign Sequence is Worth Mixed Graphs of Nodes** | [Paper](https://neurips.cc/virtual/2025/poster/117401) |
| **OmniBench: Towards The Future of Universal Omni-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/121644) Â· [Project](https://m-a-p.ai/OmniBench/) |
| **OpenMMEgo: Enhancing Egocentric Understanding for LMMs with Open Weights and Data** | [Paper](https://neurips.cc/virtual/2025/poster/119544) |
| **OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata** | [Paper](https://neurips.cc/virtual/2025/poster/121611) Â· [Project](https://deepscenario.github.io/OrthoLoC) |
| **PC-Net: Weakly Supervised Compositional Moment Retrieval via Proposal-Centric Network** | [Paper](https://neurips.cc/virtual/2025/poster/116386) Â· [GitHub](https://github.com/mingyao1120/PC-Net) |
| **Panoptic Captioning: An Equivalence Bridge for Image and Text** | [Paper](https://neurips.cc/virtual/2025/poster/118605) Â· [Project](https://visual-ai.github.io/pancap/) |
| **Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers** | [Paper](https://neurips.cc/virtual/2025/poster/121461) Â· [Project](https://paper2poster.github.io/) |
| **QuARI: Query Adaptive Retrieval Improvement** | [Paper](https://neurips.cc/virtual/2025/poster/118001) |
| **ReID5o: Achieving Omni Multi-modal Person Re-identification in a Single Model** | [Paper](https://neurips.cc/virtual/2025/poster/118107) Â· [GitHub](https://github.com/Zplusdragon/ReID5o_ORBench) |
| **Scaling Image Geo-Localization to Continent Level** | [Paper](https://neurips.cc/virtual/2025/poster/115618) |
| **Seeing the Arrow of Time in Large Multimodal Models** | [Paper](https://neurips.cc/virtual/2025/poster/118287) Â· [Project](https://vision.cs.utexas.edu/projects/SeeAoT/) |
| **SegMASt3R: Geometry Grounded Segment Matching** | [Paper](https://neurips.cc/virtual/2025/poster/119228) Â· [Project](https://segmast3r.github.io/) |
| **Show-o2: Improved Native Unified Multimodal Models** | [Paper](https://neurips.cc/virtual/2025/poster/119700) Â· [GitHub](https://github.com/showlab/Show-o) |
| **Spatially-aware Weights Tokenization for NeRF-Language Models** | [Paper](https://neurips.cc/virtual/2025/poster/115076) |
| **Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval** | [Paper](https://neurips.cc/virtual/2025/poster/115850) |
| **UFM: A Simple Path towards Unified Dense Correspondence with Flow** | [Paper](https://neurips.cc/virtual/2025/poster/117892) Â· [Project](https://uniflowmatch.github.io/) |
